import os

import streamlit as st
import torch
from dotenv import load_dotenv

from src.llm import chat
from src.retrievers import RetrievePipeline

st.set_page_config(layout="wide")

os.environ["KMP_DUPLICATE_LIB_OK"] = "True"

device = torch.device(
    "cuda"
    if torch.cuda.is_available()
    else "mps" if torch.backends.mps.is_available() else "cpu"
)

load_dotenv(override=True)


@st.cache_resource
def init_retrieve_pipeline(device: str) -> RetrievePipeline:
    return RetrievePipeline(device=device)


retrieve_pipe = init_retrieve_pipeline(device)


def initialize_session_states() -> None:
    if "messages" not in st.session_state:
        st.session_state["messages"] = []


def sidebar_strategy_selector() -> str:
    st.sidebar.header("–í—ã–±–æ—Ä —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏")
    strategies = ["SummaryEmb", "ColQwen", "ColQwen+SummaryEmb"]
    default_index = strategies.index("ColQwen+SummaryEmb") if "ColQwen+SummaryEmb" in strategies else 0
    return st.sidebar.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–æ–∏—Å–∫–∞:", strategies, index=default_index)


def display_chat_history() -> None:
    for message in st.session_state["messages"]:
        role = message["role"]
        content = message["content"]
        with st.chat_message(role):
            if role == "user":
                st.markdown(content)
            else:
                answer_text, image_paths = content
                if image_paths:
                    st.markdown("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É:")
                    num_images = len(image_paths)
                    cols = st.columns(num_images)
                    for i, path in enumerate(image_paths):
                        with cols[i]:
                            st.image(path, caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}", use_container_width=True)
                st.markdown("**–û—Ç–≤–µ—Ç:**\n" + answer_text.lstrip())


def handle_user_query(query: str, strategy: str) -> None:
    st.session_state["messages"].append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)

    with st.status("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞...", expanded=False) as status:
        status.update(label="–≠—Ç–∞–ø 1/2: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π...")
        image_paths = retrieve_pipe.retrieve(query, strategy)
        status.update(label="–≠—Ç–∞–ø 2/2: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –ø–æ –Ω–∞–π–¥–µ–Ω–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º...")
        structured_query = [{"role": "user", "content": [{"type": "text", "text": query}]}]
        answer_text = chat(structured_query, image_paths if image_paths else None)
        status.update(label="–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!", state="complete", expanded=False)

    st.session_state["messages"].append({"role": "assistant", "content": (answer_text, image_paths)})
    with st.chat_message("assistant"):
        if image_paths:
            st.markdown("–†–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∑–∞–ø—Ä–æ—Å—É:")
            num_images = len(image_paths)
            cols = st.columns(num_images)
            for i, path in enumerate(image_paths):
                with cols[i]:
                    st.image(path, caption=f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {i+1}", use_container_width=True)
        st.markdown("**–û—Ç–≤–µ—Ç:**\n" + answer_text.lstrip())


def main():
    st.title("–ú—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–∞—è RAG —Å–∏—Å—Ç–µ–º–∞ ü§ñ")
    initialize_session_states()
    clear_chat_button = st.sidebar.button("–û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞")
    if clear_chat_button:
        st.session_state.messages = []
        st.rerun()

    strategy = sidebar_strategy_selector()
    display_chat_history()
    user_query = st.chat_input("–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–≥–æ –ø–æ–∏—Å–∫–∞")

    if user_query:
        handle_user_query(user_query, strategy)
        st.rerun()


if __name__ == "__main__":
    main()